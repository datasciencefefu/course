{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmkvO2vRiGN"
      },
      "source": [
        "# **ОСНОВЫ СТАТИСТИЧЕСКОГО И ИССЛЕДОВАТЕЛЬСКОГО АНАЛИЗА ДАННЫХ НА PYTHON**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A358S_Yo2r2M"
      },
      "source": [
        "# Предисловие"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYBT7Ueh2B5X"
      },
      "source": [
        "В  основу  учебного  пособия  положен  цикл  лекций  и практических работ по дисциплинам «Специальные ИТ для анализа данных и расчетов», «Суперкомпьютерные вычисленияи  оптимизация  в  моделировании  физических  процессов», «Управление ИТ-проектами», «Цифровая обработка информации», читаемым в Дальневосточном федеральном университете. В нем в краткой и доступной форме излагаются  основы  статистического и исследовательского анализа данных. Анализ данных - широкое понятие. В самом общем смысле это исследования, связанные с обработкой специальными методами и алгоритмами многомерной системы данных, имеющей множество параметров. В процессе анализа исследователь формирует определённое\n",
        "представление о характере явления, описываемого этими данными.\n",
        "Анализ данных нельзя рассматривать только как обработку информации после ее сбора, ведь это прежде всего средство проверки гипотез и решения задач исследователя, работающего практически в любой области современного знания.\n",
        "\n",
        "Материал учебного пособия делится на четыре главы. В первой главе описывается роль анализа данных всовременном мире. Во второй главе дается материал, посвящённый практическому применению математической статистики и теории вероятностей при анализе данных на Python. Для иллюстрации основных понятий и определений использованы возможности библиотек Matplotlib, Plotly, Pandas, Seaborn, NumPy, SciPy. В третьей главе приводится описание методов сбора и предобработки данных. Рассмотрены основные объекты библиотеки Pandas: DataFrame и Series. Большое внимание уделено приёмам работы с регулярными выражениями с использованием библиотеки re, парсингу страниц (библиотеки requests для отправления\n",
        "HTTP-запросов и BeautifulSoup для преобразования HTML-файла в древовидную структуру) и методам обработки данных в формате JSON. Описаны способы работы с пропусками в датасетах, в том числе удаление дубликатов и объединение таблиц. В четвертой главе рассматриваются основные методы визуализации  данных  с  использованием  библиотек  Pandas, Matplotlib, Seaborn и Plotly. \n",
        "\n",
        "Практические материалы и задания для студентов выполнены с использованием Google Colaboratory - бесплатной интерактивной облачной среды для работы с кодом от Google. Для успешного освоения материала, представленного в учебном пособии, необходимо владение основами линейной алгебры и математического анализа, а также базовыми навыками программирования на языке Python.\n",
        "\n",
        "Данное учебное пособие предназначено для специалистовв различных областях математической статистики, анализа данных, информатики, теоретической и статистической физики, компьютерного моделирования, а также для аспирантов и студентов  вузов  естественнонаучных  и  физико-технических направлений подготовки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDXPc_q6S4v2"
      },
      "source": [
        "# Роль анализа данных в современном мире\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXuyge444XCr"
      },
      "source": [
        "> «Большие данные будут формировать наше общество. Если эти технологии окажутся не совместимы с человеческими ценностями, то они нанесут непоправимый ущерб человечеству. ... <br>Сейчас исторический момент, чтобы выбрать правильный путь и получать выгоды от возможностей, которые стоят перед нами».<br><br>\n",
        "Gerd Gigerenzer<br>\n",
        "Max Planck Institute for Human Development\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RQi1Q9Mh9Ra"
      },
      "source": [
        "С каждым днем источников данных становится все больше: социальные сети, метеорологическая статистика, финансовые операции, мобильные приложения, информация о местонахождении абонентов сетей мобильной сотовой связи и данные с устройств аудио- и видеорегистрации, но больше всего информации создается при помощи интернета вещей (Internet of things) — более 80% всех данных. Что же такое данные? Это факты, тексты, картинки, звуки, логи, фрагменты кода, то есть информация, с которой мы взаимодействуем, храним, передаем и обрабатываем.\n",
        "\n",
        "\n",
        "\n",
        "> **Данные** — сведения об объектах и явлениях окружающего мира, выраженные в форме, доступной для восприятия, передачи и хранения. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Каждую секунду человек производит и потребляет данные, смартфоны и компьютеры также генерируют и скачивают данные, обмениваются ими с серверами в интернете и т.д. \n",
        "\n",
        "Подсчитано, что объем данных, собранных за пять тысячелетий с момента изобретения письма до 2003 г., составляет около пяти эксабайт. В наше время такое же количество информации генерируется каждые два дня. По прогнозам IDC количество данных на планете будет как минимум удваиваться каждые два года."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQbFoANprB4d"
      },
      "source": [
        "![0datacreate.png](https://github.com/datasciencefefu/course/raw/main/images/0datacreate.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stYUoyl0jO7a"
      },
      "source": [
        "Однако сами по себе «данные, как горная порода, – бесполезны без извлекающих золото специалистов и технологий». Сегодня залогом успеха любой компании становится активная работа с имеющейся информацией. Каждый день собирается огромное количество информации о пользователях, их действиях и поведении. Современные компании ищут специалистов, способных правильно подготовить и обработать данные, владеющих методами моделирования, анализа и интерпретации результатов. \n",
        "\n",
        "Инструменты аналитики используются для решения текущих проблем и поиска управленческих стратегий для предотвращения сложностей в будущем. Для\n",
        "некоторых предприятий данные и аналитика становятся главной движущей\n",
        "силой и фундаментом цифровой трансформации. Данные, их обработка и глубокий анализ позволяют выявлять тенденции, искать слабые места, выдвигать гипотезы и делать достоверные прогнозы. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M66xAld_jV10"
      },
      "source": [
        "## Анализ больших данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXm1UqNmjbP2"
      },
      "source": [
        "В современном мире, где информация часто обновляется и поступает из разных источников, специалистам в сфере Data Science приходится работать с огромными массивами данных. Объем, разнообразие и скорость их поступления создают новые уникальные проблемы для анализа. \n",
        "\n",
        "\n",
        "> **Большие данные** — объемные, быстро растущие в количестве и многообразные по структуре и типам информации данные. Также под этим термином понимается совокупность технологий для работы с большими массивами данных. \n",
        "\n",
        "\n",
        "\n",
        "Термин Big Data относится к наборам данных, размер которых превосходит возможности типичных баз данных по хранению, управлению и анализу информации. В бытовом смысле большими данными можно считать то, что не помещается в оперативную память вашего компьютера. Термин появился в 2008 г. благодаря статье редактора Nature Клиффорда Линча и сразу был подхвачен маркетологами. Всплеск интереса к большим данным во многом связан с ростом вычислительных мощностей, позволяющих их обрабатывать.  В настоящее время за развитием технологий Big Data следят множество компаний. В 2011 г. большие данные уже использовались такими гигантами бизнеса как Hewlett-Packard, IBM, Microsoft. В 2015 г. доля компаний, использующих большие данные, составляла 17% в мире. Сегодня доля таких компаний превышает 50%.\n",
        "\n",
        "Понятие Big Data является собирательным и используется для обозначения технологий, которые обеспечивают переход в новую эру цифровых коммуникаций и обработку данных. Технологии Big Data – серия инструментов и методов обработки структурированных и неструктурированных данных огромных объемов и различных форматов. Данные технологии применяются для получения воспринимаемых человеком результатов, эффективных в условиях непрерывного прироста и распределения информации по многочисленным узлам вычислительной сети. Технологии Big Data сформировались еще в конце 2000-х годов в качестве альтернативы традиционным системам управления базами данных и решениям класса Business Intelligence. В настоящее время большинство крупнейших поставщиков информационных технологий для организаций в своих деловых стратегиях используют понятие «большие данные», а основные аналитики рынка информационных технологий посвящают концепции отдельные исследования.\n",
        "\n",
        "Сегодня технологии Big Data активно используется в самых разных отраслях – от банковского до аграрного сектора. \n",
        "\n",
        "* IТ-компании по всему миру, являющиеся одним из крупнейших пользователей больших данных, используют их для оптимизации своей работы, повышения производительности труда сотрудников и минимизации расходов. Комбинируя технологии больших данных с технологиями искусственного интеллекта, IТ-сектор постоянно внедряет инновации для поиска решений даже для самых сложных проблем.\n",
        "\n",
        "* Образование больше не ограничивается физическими рамками учебной комнаты, в том числе из-за начавшейся в 2019 г. пандемии коронавируса, обучение постепенно переходит в онлайн. Данные помогают повысить успеваемость, вовремя назначив репетитора, или выстроить индивидуальную траекторию обучения.\n",
        "\n",
        "* Использование данных с датчиков улучшает стратегии поставок и повышает качество продукции. Также большие данные помогают создать прозрачную инфраструктуру, тем самым выявляя и прогнозируя слабые места, которые могут негативно повлиять на бизнес.\n",
        "\n",
        "* С помощью прогнозной аналитики медицинские организации могут предоставлять индивидуальные услуги отдельным пациентам. Кроме того, носимые устройства для фитнеса, телемедицина, дистанционный мониторинг — все это благодаря большим данным помогает изменить жизнь к лучшему.\n",
        "\n",
        "* Данные становятся таким же важным фактором производства, как трудовые ресурсы и производственные активы. Благодаря аналитике больших данных компании оптимизируют продажи и логистику, лучше узнают клиентов и разрабатывают наиболее подходящие им предложения. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn8xfW50jvJb"
      },
      "source": [
        "## Характеристики больших данных\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTD8Dx77j27n"
      },
      "source": [
        "Анализ больших данных (Big Data) начинается с их сбора. Информацию получают отовсюду: с наших смартфонов, кредитных карт, программных приложений, автомобилей. Из-за разных форматов и путей возникновения Big Data отличаются рядом характеристик, определенных в описательной модели больших данных под названием 3V (VVV): Volume (объёмы данных), Velocity (скорость накопления и обработки данных) и Variety (разнообразие источников и типов данных). Набор признаков 3V (VVV) был создан Douglas Laney из компании Meta Group в 2001 г. с целью указания на равную значимость управления данными по всем трём аспектам. Рассмотрим приведенные характеристики подробнее:\n",
        "1. Volume (объём). Огромные объёмы данных, которые организации получают из бизнес-транзакций, интеллектуальных (IoT) устройств, промышленного оборудования, социальных сетей и других источников, нужно где-то хранить. Еще сравнительно недавно это было существенной проблемой, но развитие систем хранения информации облегчило ситуацию и сделало хранение и доступ к информации доступнее.\n",
        "2. Velocity (скорость). Чаще всего этот пункт относится к скорости поступления данных в реальном времени. В более широком понимании характеристика объясняет необходимость высокоскоростной обработки из-за изменения темпов прироста информации (всплесков активности).\n",
        "3. Variety (вариативность). Разнообразие больших данных проявляется в их форматах: структурированные данные из клиентских баз, неструктурированные текстовые, видео- и аудиофайлы, а также частично структурированная информация из нескольких источников. Если раньше данные можно было собирать только из электронных таблиц, то сегодня данные поступают как в формате электронных писем, так и голосовых сообщений.\n",
        "\n",
        "В дальнейшем возникли интерпретации описательной модели Big Data с четырьмя V (добавлялась veracity – достоверность), пятью V (viability – жизнеспособность и value – ценность), и даже семью V (variability – способность к изменению и visualization – визуализация). Но компания IDC, например, интерпретирует именно четвёртое V как value (ценность), подчеркивая экономическую целесообразность обработки больших объёмов данных в соответствующих условиях.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oolyqmfxBgY"
      },
      "source": [
        "## Инструменты анализа данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsELwN60j9jK"
      },
      "source": [
        "В области анализа данных и интерактивных научно-исследовательских расчетов с визуализацией результатов используется довольно большое количество предметно-ориентированных языков программирования и инструментов – как с открытым исходным кодом, так и коммерческих – например, Python, R, Matlab, Stata, SAS и другие. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMKejjCXj-s6"
      },
      "source": [
        "Рынок компьютерных программ для статистического анализа данных характеризуется высокой конкуренцией, нередки случаи консолидации и поглощений компаний-разработчиков. \n",
        "Перед пользователями различных категорий встает вопрос выбора оптимального программного продукта для поиска верных ответов на существующие вопросы. Очевидно, что оптимальным является вариант, сочетающий в себе необходимые функциональные возможности, высокое качество работы и умеренную цену. При выборе программы для анализа данных следует учитывать следующие параметры:\n",
        "-\tсоответствие характеру решаемых задач;\n",
        "- объем обрабатываемых данных;\n",
        "-\tтребования, предъявляемые к квалификации пользователя (уровень знаний в области статистики);\n",
        "-\tимеющееся в наличии компьютерное оборудование.\n",
        "\n",
        "Сравнительно недавнее появление улучшенных библиотек (прежде всего, Pandas – начало разработки в 2008 г.) для Python сделало его серьезным конкурентом в решении задач манипулирования данными. В сочетании с достоинствами Python как универсального языка программирования это делает его отличным выбором для анализа данных, поэтому на сегодняшний день Python считается одним из наиболее востребованных языков в Data Science.\n",
        "\n",
        "Python приобретает все большую популярность не только среди аналитиков данных. По данным одного из самых известных рейтингов TIOBE Python с 2008 г. прочно удерживается в восьмерке наиболее популярных языков программирования. Google, Яндекс, Национальное управление по воздухоплаванию и исследованию космического пространства США (NASA) и многие другие известные компании активно используют Python.\n",
        "Проблему лицензирования программного обеспечения снимает то, что свободно распространяемые реализации языка Python существуют для всех популярных операционных систем: Linux, Mac OS, Windows, Android, iOS и др. \n",
        "\n",
        "В настоящее время существуют две несовместимые между собой версии \n",
        "Python — Python 2 и Python 3. Однако в январе 2020 г. команда разработчиков Python 3 заявила, что прекращают поддержку Python 2. Facebook, Instagram и многие другие крупные компании уже перенесли большую часть своего кода с Python 2 на Python 3. На настоящий момент последняя доступная для скачивания версия Python - Python 3.9.5 \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whJjgUVMzvih"
      },
      "source": [
        "\n",
        "## Инструменты Python для анализа данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U43QlzTBPA0a"
      },
      "source": [
        "Для анализа и обработки данных в материалах данного учебного пособия будет использоваться язык Python, так как он является оптимальным средством работы с данными благодаря огромному количеству полезных библиотек, написанных для него. \n",
        "\n",
        "> **Библиотеки** - это модули Python. То есть это самостоятельные, объединённые технически и логически, именованные части Python кода.\n",
        "\n",
        "\n",
        "\n",
        "В Python предусмотрено большое количество библиотек для хранения и обработки данных. Рассмотрим наиболее популярные из них:\n",
        "\n",
        "*   Pandas - обработка структурированных данных;\n",
        "*   NumPy - поддержка больших многомерных массивов и матриц, вместе с большой библиотекой высокоуровневых математических функций для операций с этими массивами;\n",
        "*   SciPy - использование математических алгоритмов и функций для выполнения научных и инженерных расчётов;\n",
        "*   Matplotlib - визуализация данных в виде двумерных графиков (включая 3D-представления)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXc-UU0ukyW7"
      },
      "source": [
        "В данном пособии будут последовательно разобраны и изучены инструменты Python, необходимые для сбора и предобработки данных, визуализации, статистического и исследовательского анализа."
      ]
    }
  ]
}